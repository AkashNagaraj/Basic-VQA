# Basic-VQA

Uses a LSTM for language encoder and a CNN for image encoding and uses attention to concentrate on important parts of the image. 

## Data 

[VQA-X](https://drive.google.com/drive/u/0/folders/1Cr9JRXDmjks_wmi-a9eIe4SWSwWKcCk7)
